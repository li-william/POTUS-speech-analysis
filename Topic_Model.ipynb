{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model for POTUS Speech Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "import random\n",
    "import textman as tx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = r'C:\\Users\\William\\Documents\\College\\SPR2018\\DS5559\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet'\n",
    "COLUMNS=['doc_id','date','pres','title','speech']\n",
    "docs = pd.DataFrame(columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pres</th>\n",
       "      <th>title</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 16, 1797</td>\n",
       "      <td>adams</td>\n",
       "      <td>Special Session Message to Congress</td>\n",
       "      <td>The personal inconveniences to the members of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>March 4, 1797</td>\n",
       "      <td>adams</td>\n",
       "      <td>Inaugural Address</td>\n",
       "      <td>When it was first perceived, in early times, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December 8, 1798</td>\n",
       "      <td>adams</td>\n",
       "      <td>Second Annual Message</td>\n",
       "      <td>Gentlemen of the Senate and Gentlemen of the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>March 23, 1798</td>\n",
       "      <td>adams</td>\n",
       "      <td>Proclamation of Day of Fasting, Humiliation an...</td>\n",
       "      <td>As the safety and prosperity of nations ultima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>December 3, 1799</td>\n",
       "      <td>adams</td>\n",
       "      <td>Third Annual Message</td>\n",
       "      <td>It is with peculiar satisfaction that I meet t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date   pres  \\\n",
       "doc_id                            \n",
       "1           May 16, 1797  adams   \n",
       "2          March 4, 1797  adams   \n",
       "3       December 8, 1798  adams   \n",
       "4         March 23, 1798  adams   \n",
       "5       December 3, 1799  adams   \n",
       "\n",
       "                                                    title  \\\n",
       "doc_id                                                      \n",
       "1                     Special Session Message to Congress   \n",
       "2                                       Inaugural Address   \n",
       "3                                   Second Annual Message   \n",
       "4       Proclamation of Day of Fasting, Humiliation an...   \n",
       "5                                    Third Annual Message   \n",
       "\n",
       "                                                   speech  \n",
       "doc_id                                                     \n",
       "1       The personal inconveniences to the members of ...  \n",
       "2       When it was first perceived, in early times, t...  \n",
       "3       Gentlemen of the Senate and Gentlemen of the H...  \n",
       "4       As the safety and prosperity of nations ultima...  \n",
       "5       It is with peculiar satisfaction that I meet t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "_id = 1\n",
    "pres = []\n",
    "for filename in os.listdir('./speeches'):\n",
    "    pres.append(filename)\n",
    "    for speech in os.listdir('./speeches/' + filename):\n",
    "        temp = open('./speeches/' + filename + '/' + speech, 'r', encoding='utf-8').readlines()\n",
    "        obj = {}\n",
    "        obj['doc_id'] = _id\n",
    "        date = re.findall('\"([^\"]*)\"', temp[1])\n",
    "        obj['date'] = date[0] if len(date) > 0 else None\n",
    "        obj['pres'] = filename\n",
    "        obj['title'] = re.findall('\"([^\"]*)\"', temp[0])[0]\n",
    "        obj['speech']= \"\".join(temp[2:])\n",
    "    \n",
    "        obj = pd.DataFrame(obj, index=[0])\n",
    "        docs = docs.append(obj, ignore_index=True)\n",
    "        _id += 1\n",
    "docs = docs.set_index(\"doc_id\")\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert corpus to tokens and vocab\n",
    "We use a function from TextMan, a bespoke library that incorporates the text processing routines used in earlier notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, vocab = tx.create_tokens_and_vocab(docs, src_col='speech')\n",
    "tokens['token_num'] = tokens.groupby(['doc_id']).cumcount()\n",
    "tokens = tokens.reset_index()[['doc_id','token_num','term_id']]\n",
    "tokens = tokens[tokens.term_id.isin(vocab[vocab.go].index)]\n",
    "tokens = tokens.set_index(['doc_id','token_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add term strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>23092</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16448</td>\n",
       "      <td>inconveniences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19972</td>\n",
       "      <td>members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27777</td>\n",
       "      <td>senate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15709</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term_id        term_str\n",
       "doc_id token_num                         \n",
       "1      0            23092        personal\n",
       "       1            16448  inconveniences\n",
       "       2            19972         members\n",
       "       3            27777          senate\n",
       "       4            15709           house"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['term_str'] = tokens.term_id.map(vocab.term)\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove insignificant words\n",
    "\n",
    "We use SKlearn's TFIDF vectorizor to quicky get a TFIDF vector space, which we use only to filter the words in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=1, stop_words='english', token_pattern=r'[A-Za-z][A-Za-z][A-Za-z]+')\n",
    "X = vectorizer.fit_transform(docs['speech'].values.tolist())\n",
    "v = pd.DataFrame(vectorizer.get_feature_names(), columns=['term_str'])\n",
    "v['idf'] = vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16271</th>\n",
       "      <td>laptop</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>landless</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>landreau</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16242</th>\n",
       "      <td>landscaping</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>landslided</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>landward</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>langdon</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>langen</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16251</th>\n",
       "      <td>langfang</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str       idf\n",
       "0              aaa  7.176906\n",
       "16271       laptop  7.176906\n",
       "16230     landless  7.176906\n",
       "16239     landreau  7.176906\n",
       "16242  landscaping  7.176906\n",
       "16244   landslided  7.176906\n",
       "16246     landward  7.176906\n",
       "16249      langdon  7.176906\n",
       "16250       langen  7.176906\n",
       "16251     langfang  7.176906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sort_values('idf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export corpus for MALLET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tx.gather_tokens(tokens, level=0, col='term_str')\\\n",
    "    .reset_index().rename(columns={'term_str':'doc_content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>personal inconveniences members senate house r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>first perceived early times middle course amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gentlemen senate gentlemen house representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>safety prosperity nations ultimately essential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>peculiar satisfaction meet congress united sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                        doc_content\n",
       "0       1  personal inconveniences members senate house r...\n",
       "1       2  first perceived early times middle course amer...\n",
       "2       3  gentlemen senate gentlemen house representativ...\n",
       "3       4  safety prosperity nations ultimately essential...\n",
       "4       5  peculiar satisfaction meet congress united sta..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.to_csv('speech-corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mallet 2.0 commands: \n",
      "  import-dir        load the contents of a directory into mallet instances (one per file)\n",
      "  import-file       load a single file into mallet instances (one per line)\n",
      "  import-svmlight   load a single SVMLight format data file into mallet instances (one per line)\n",
      "  info              get information about Mallet instances\n",
      "  train-classifier  train a classifier from Mallet data files\n",
      "  classify-dir      classify data from a single file with a saved classifier\n",
      "  classify-file     classify the contents of a directory with a saved classifier\n",
      "  classify-svmlight classify data from a single file in SVMLight format\n",
      "  train-topics      train a topic model from Mallet data files\n",
      "  infer-topics      use a trained topic model to infer topics for new documents\n",
      "  evaluate-topics   estimate the probability of new documents given a trained model\n",
      "  prune             remove features based on frequency or information gain\n",
      "  split             divide data into testing, training, and validation portions\n",
      "  bulk-load         for big input files, efficiently prune vocabulary and import docs\n",
      "Include --help with any option for more information\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Xmx1024m\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path} import-file --input speech-corpus.csv --output novels-corpus.mallet --keep-sequence TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{mallet_path} train-topics --input speech-corpus.mallet --num-topics {20} --num-iterations {1000} \\\n",
    "--output-doc-topics speech-topics.txt \\\n",
    "--output-topic-keys speech-topics-keys.txt \\\n",
    "--word-topic-counts-file speech-word-topic-counts-file.txt \\\n",
    "--topic-word-weights-file speech-topic-word-weights-file.txt \\\n",
    "--xml-topic-report speech-topic-report.xml \\\n",
    "--xml-topic-phrase-report speech-topic-phrase-report.xml \\\n",
    "--show-speech-interval {100} \\\n",
    "--use-symmetric-alpha false  \\\n",
    "--optimize-interval 100 \\\n",
    "--diagnostics-file speech-diagnostics.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
