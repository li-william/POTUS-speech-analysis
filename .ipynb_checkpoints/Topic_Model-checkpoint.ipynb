{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model for POTUS Speech Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import re\n",
    "import random\n",
    "import textman as tx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mallet_path = '/Users/williamLi/Documents/College/Semester\\ 6/ds/mallet-2.0.6/bin/mallet'\n",
    "COLUMNS=['doc_id','date','pres','title','speech']\n",
    "docs = pd.DataFrame(columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pres</th>\n",
       "      <th>speech</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August 10, 1927</td>\n",
       "      <td>coolidge</td>\n",
       "      <td>We have come here to dedicate a cornerstone th...</td>\n",
       "      <td>Address at the Opening of Work on Mount Rushmo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>December 8, 1925</td>\n",
       "      <td>coolidge</td>\n",
       "      <td>Members of the Congress: In meeting the consti...</td>\n",
       "      <td>Third Annual Message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>December 6, 1923</td>\n",
       "      <td>coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>First Annual Message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October 20, 1925</td>\n",
       "      <td>coolidge</td>\n",
       "      <td>Mr. Moderator, Members Of The Council:\\nIt is ...</td>\n",
       "      <td>Message Regarding Relationship of Church and S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>March 4, 1925</td>\n",
       "      <td>coolidge</td>\n",
       "      <td>\\nMy Countrymen:\\n\\nNo one can contemplate cur...</td>\n",
       "      <td>Inaugural Address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date      pres  \\\n",
       "doc_id                               \n",
       "1        August 10, 1927  coolidge   \n",
       "2       December 8, 1925  coolidge   \n",
       "3       December 6, 1923  coolidge   \n",
       "4       October 20, 1925  coolidge   \n",
       "5          March 4, 1925  coolidge   \n",
       "\n",
       "                                                   speech  \\\n",
       "doc_id                                                      \n",
       "1       We have come here to dedicate a cornerstone th...   \n",
       "2       Members of the Congress: In meeting the consti...   \n",
       "3       Since the close of the last Congress the Natio...   \n",
       "4       Mr. Moderator, Members Of The Council:\\nIt is ...   \n",
       "5       \\nMy Countrymen:\\n\\nNo one can contemplate cur...   \n",
       "\n",
       "                                                    title  \n",
       "doc_id                                                     \n",
       "1       Address at the Opening of Work on Mount Rushmo...  \n",
       "2                                    Third Annual Message  \n",
       "3                                    First Annual Message  \n",
       "4       Message Regarding Relationship of Church and S...  \n",
       "5                                       Inaugural Address  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "_id = 1\n",
    "for filename in os.listdir('./speeches'):\n",
    "    if filename == '.DS_Store':\n",
    "        continue\n",
    "    for speech in os.listdir('./speeches/' + filename):\n",
    "        temp = open('./speeches/' + filename + '/' + speech, 'r', encoding='utf-8').readlines()\n",
    "        obj = {}\n",
    "        obj['doc_id'] = _id\n",
    "        date = re.findall('\"([^\"]*)\"', temp[1])\n",
    "        obj['date'] = date[0] if len(date) > 0 else None\n",
    "        obj['pres'] = filename\n",
    "        obj['title'] = re.findall('\"([^\"]*)\"', temp[0])[0]\n",
    "        obj['speech']= \"\".join(temp[2:])\n",
    "    \n",
    "        obj = pd.DataFrame(obj, index=[0])\n",
    "        docs = docs.append(obj, ignore_index=True)\n",
    "        _id += 1\n",
    "docs = docs.set_index(\"doc_id\")\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert corpus to tokens and vocab\n",
    "We use a function from TextMan, a bespoke library that incorporates the text processing routines used in earlier notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens, vocab = tx.create_tokens_and_vocab(docs, src_col='speech')\n",
    "tokens['token_num'] = tokens.groupby(['doc_id']).cumcount()\n",
    "tokens = tokens.reset_index()[['doc_id','token_num','term_id']]\n",
    "tokens = tokens[tokens.term_id.isin(vocab[vocab.go].index)]\n",
    "tokens = tokens.set_index(['doc_id','token_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add term strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_id</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>7179</td>\n",
       "      <td>come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9118</td>\n",
       "      <td>dedicate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8201</td>\n",
       "      <td>cornerstone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18308</td>\n",
       "      <td>laid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14872</td>\n",
       "      <td>hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  term_id     term_str\n",
       "doc_id token_num                      \n",
       "1      0             7179         come\n",
       "       1             9118     dedicate\n",
       "       2             8201  cornerstone\n",
       "       3            18308         laid\n",
       "       4            14872         hand"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['term_str'] = tokens.term_id.map(vocab.term)\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove insignificant words\n",
    "\n",
    "We use SKlearn's TFIDF vectorizor to quicky get a TFIDF vector space, which we use only to filter the words in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=1, stop_words='english', token_pattern=r'[A-Za-z][A-Za-z][A-Za-z]+')\n",
    "X = vectorizer.fit_transform(docs['speech'].values.tolist())\n",
    "v = pd.DataFrame(vectorizer.get_feature_names(), columns=['term_str'])\n",
    "v['idf'] = vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaa</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16271</th>\n",
       "      <td>laptop</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>landless</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16239</th>\n",
       "      <td>landreau</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16242</th>\n",
       "      <td>landscaping</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16244</th>\n",
       "      <td>landslided</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>landward</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16249</th>\n",
       "      <td>langdon</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>langen</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16251</th>\n",
       "      <td>langfang</td>\n",
       "      <td>7.176906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term_str       idf\n",
       "0              aaa  7.176906\n",
       "16271       laptop  7.176906\n",
       "16230     landless  7.176906\n",
       "16239     landreau  7.176906\n",
       "16242  landscaping  7.176906\n",
       "16244   landslided  7.176906\n",
       "16246     landward  7.176906\n",
       "16249      langdon  7.176906\n",
       "16250       langen  7.176906\n",
       "16251     langfang  7.176906"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.sort_values('idf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export corpus for MALLET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = tx.gather_tokens(tokens, level=0, col='term_str')\\\n",
    "    .reset_index().rename(columns={'term_str':'doc_content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>come dedicate cornerstone laid hand almighty t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>members congress meeting constitutional requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>since close last congress nation lost presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>moderator members council understanding purpos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>countrymen one contemplate current conditions ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id                                        doc_content\n",
       "0       1  come dedicate cornerstone laid hand almighty t...\n",
       "1       2  members congress meeting constitutional requir...\n",
       "2       3  since close last congress nation lost presiden...\n",
       "3       4  moderator members council understanding purpos...\n",
       "4       5  countrymen one contemplate current conditions ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.to_csv('speech-corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dirname path\r\n",
      "usage: dirname path\r\n",
      "Unrecognized command: \r\n",
      "Mallet 2.0 commands: \r\n",
      "\r\n",
      "  import-dir        load the contents of a directory into mallet instances (one per file)\r\n",
      "  import-file       load a single file into mallet instances (one per line)\r\n",
      "  import-svmlight   load SVMLight format data files into Mallet instances\r\n",
      "  train-classifier  train a classifier from Mallet data files\r\n",
      "  classify-dir      classify data from a single file with a saved classifier\r\n",
      "  classify-file     classify the contents of a directory with a saved classifier\r\n",
      "  train-topics      train a topic model from Mallet data files\r\n",
      "  infer-topics      use a trained topic model to infer topics for new documents\r\n",
      "  evaluate-topics   estimate the probability of new documents under a trained model\r\n",
      "  hlda              train a topic model using Hierarchical LDA\r\n",
      "  prune             remove features based on frequency or information gain\r\n",
      "  split             divide data into testing, training, and validation portions\r\n",
      "\r\n",
      "Include --help with any option for more information\r\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: dirname path\n",
      "usage: dirname path\n",
      "Error: Could not find or load main class cc.mallet.classify.tui.Csv2Vectors\n",
      "Caused by: java.lang.ClassNotFoundException: cc.mallet.classify.tui.Csv2Vectors\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path} import-file --input speech-corpus.csv --output speech-corpus.mallet --keep-sequence TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: {mallet_path}: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!{mallet_path} train-topics --input speech-corpus.mallet --num-topics {num_topics} --num-iterations {num_iters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
